\documentclass[a4paper,11pt]{article}


\usepackage[latin1]{inputenc}

\newcommand{\nnsection}[1]{
\section*{#1}
\addcontentsline{toc}{section}{#1}
}

\begin{document}

\begin{center}
\vspace{20pt}
\textbf{\large Huffman coding}\\
\vspace{10pt}
\textbf{Johan Montelius}\\
\vspace{10pt}
\today{}
\end{center}


\nnsection{Getting started}

In this seminar session we will look at different ways to represent
data, using lists, trees and tuples to find the best
representation. The {\em best representation} could of course mean
many things, we might need a representation that gives us efficient
code or we might want a representation that is easy to explain,
implement and maintain. We will start by using quite simple
representations and then refine them to gain better performance.

To have something to work with we will implement the {\em Huffman}
encoding and decoding functions. You should do some reading on Huffman
coding, this text will not explain the algorithm but how to implement it.

\section{Huffman overview}

Huffman coding can divided into two parts, one part is how to
construct the coding tables and the other, much simpler, is how to
encode or decode a text using the tables. 

The idea behind Huffman coding is of course to encode frequent
characters with few bits and infrequent characters with more bits. To
keep things simple we will represent sequences of bits as lists of
zeros and ones but this could of course be changes if we intend to do a
real implementation that reads and writes to files. For our
experiments it is sufficient.

The table should give a one to one maping from characters to codes but
we might use one representation when we encode text and another when
we decode text; the information it holds is the same but we might want
to do this for efficiency.

Once we are done we will have a module that defines the following functions:

\begin{itemize}
\item {tree(Sample):} create a {\em Huffman tree} given a sample text.
\item {encode\_table(Tree):} create an {\em encoding table} containing the maping from characters to codes given a Huffman tree.
\item {decode\_table(Tree):} create an {\em decoding table} containing the maping from codes to characters given a Huffman tree.
\item {encode(Text, Table):} encode the text using the maping in the table, return a sequence of bits.
\item {decode(Sequence, Table):} decode the bit sequence using the maping in table, return a text.
\end{itemize}

Start by defining the module, some compile directives, things that
are good to have and dummy code for the functions.

\begin{verbatim}
-module(huffman).

-compile(export_all).

sample() -> "the quick brown fox jumps over the lazy dog
     this is a sample text that we will use when we build 
     up a table we will only handle lower case letters and
     no punctuation symbols the frequency will of course not 
     represent english but it is probably not that far off".

text() -> "this is something that we should encode".

test() ->
    Sample = sample(),
    Tree = tree(Sample),
    Encode = encode_table(Tree),
    Decode = decode_table(Tree),
    Text = text(),
    Seq = encode(Text, Encode),
    Text = decode(Seq, Decode).
 
tree(_Sample) -> na.

encode_table(_Tree) -> na.

decode_table(_Tree) -> na.

encode(_Text, _Table) -> na.

decode(_Seq, _Table) -> na.
\end{verbatim}

\section{the table}

In order to create the Huffman tree we need first to find out the frequency
distribution in our sample text. Once we have the frequency
distribution we can start building the tree.

\begin{verbatim}
tree(Sample) -> Freq = freq(Sample),
                huffman(Freq).
\end{verbatim}

The sample is of course a list of characters ({\tt [102,111,111]} or
{\tt [\$f,\$o,\$o]} as we can write in Erlang), you should run through
this list and collect the frequencies of the characters. If ``foo''
was the sample text we should have the frequencies {\em f/1}, {\em
  o/2}. How would you represent this information? Note that you need
not know beforehand which characters that will occur in the sample.

You will probably end up with a structure that looks like this, but
how you represent the frequencies is up to you.

\begin{verbatim}
freq(Sample) -> freq(Sample, ...).

freq([], Freq) -> 
      Freq;
freq([Char|Rest], Freq) ->
      freq(Rest, ...). 
\end{verbatim}

Now once we have the frequencies we will create a Huffman tree. This
is simpler than you might think but before you read further you must
understand why we create a tree and what properties it should have. If
you started to read this with out understanding how Huffman coding
works this is the time to stop reading.

\subsection{the Huffman tree}

OK, so a Huffman tree is a tree with the characters in the leafs but
the low frequency characters have long branches and high frequency
characters have short branches. Assume we represent a leaf with a
single character and a node as a simple tuple with two branches: {\tt
  \{Left, Right\}}. 

If you turn your table into an ordered sequence of leafs where each
leaf represents a character and its frequency. The ``foo'' example
above would correspond to the sequence {\tt [\{\$f, 1\},\{\$o,2\}]}.
You could also view this as a frequency table where each entry is a
tuple {\tt \{Tree, Freq\}}, after all, a single character is a leaf.

Now, assuming we have such a sequence, what would happen if we took
the two smallest elements (lowest frequencies) and combined them into
a new node {\tt \{\{C1,C2\}, F1+F2\}} and added the node to the
remaining sequence while keeping the sequence sorted? Can we repeat
this process, what will the final result be?

How do we represent the sequence so that it is easy to find the two
smallest elements? How do we keep this representation? What is the
final result when you only have one element in your sequence?

\subsection{the encoding table}

I assume now that you have a Huffman tree and it is time to extract
the codes. The codes are of course hidden in the tree in the branches
and the code of a character is the path to the leaf holding the
character ({\em left}, {\em left}, {\em right}, {\em left} or {\em
  0,0,1,0}).

Traverse the tree, and collect the characters in the leafs. Keep track
of the path to the leaf and record this path as a sequence of zeros
and ones. When you're done you should have something like
{\tt [\{\$f, [ 1,1,0]\}, \{\$0, [1,0,1,0]\}, ...]}, or whatever the tree
looks like.

Start by writing a function that only collects the characters, once
this is mastered you can start to keep track of the path.

\subsection{half way}

Half-way there might be an exaggeration but at lest you're now done
with the first part, you have a maping from characters to Huffman
codes. It's represented by a list of tuples {\tt \{\$f, [1,1,0]\}},
one for each characters. Time to use this table in the encoding and
decoding.

\section{Huffman encoding}

This is simple, we have a text represented as a list of characters and
for each character we have a sequence of bits found in the table. You
could probably create something very simple that works 

If you manage to implement the encoder you should be able to turn the
text ``this is somethin...'' into a list of bits {\tt
  \{[1,1,0,1,0,1,0, ...]}.

Stop here an ponder what the time complexity is. You will of course
have a linear factor, depending on the length of the text, since the
text is encoded character by character but you might have other
factors. What is the the time complexity of looking up a character in
the table? What is the complexity of producing the final sequence of bits?

I'm quite sure that your original code is open for improvements but
let's leave it for now.

\section{Huffman decoding}

Decoding is slightly more tricky since we do not know exactly how many
bits are used to code each character. If we have a sequence
{\tt [1,1,0,1,0,1,0, ...]} it could be that the first four bits is a
  {\em t} and the following three is an {\em i} but we do not know;
  what we do know is that thanks to Huffman it is only possible to
  decode it in one way given a table with Huffman codes.

We will do a very simple implementation of the decoding and actually
use the same table as wee used in the encoding phase; we will later see
how to improve this. 

Start by looking at the bit sequence, assume that one bit is used in the coding and then
search the table for a character with this pattern ({\tt [1]}). If
a character is found, problem solved, if not, look for a character
using two bits ({\tt [1,0]}). Let's implement this function first
and see what we have, it will work and will probably not take that much time.

Your solution might look something like this:

\begin{verbatim}
decode([], _Table) ->
     [];
decode(Seq, Table) ->
     {Char, Rest} = decode_char(Seq, 1, Table),
     decode(Rest, Table).

decode_char(Seq, N, Table) ->
     {Code, Rest} = lists:split(N, Seq),
     case lists:keyfind(Code, 2, Table) of
       ... ->
             ...;
       false ->
             decode_char(..., ..., Table)
      end.
\end{verbatim}

I'm using some functions from the {\em lists library}, you should look
these up and understand how they work. If you fill in the blanks
you're up and running, you have your first Huffman encoder/decoder.

Make sure that it works correctly, by testing the smaller functions
and make sure that they behave correctly, then work your way
up. Always test the corner cases i.e. when lists are empty etc before
trying more complicated tasks.

\section{Performance}

Let's now run some performance tests. You need to find a large text
that you can use to benchmark the program. You would also need to find
a sample text of the given language that gives you the correct
frequencies but we can cheat and use the text it self to do the
frequency analysis. 

One thing that you have to look out for is that you have to make sure
that you sample text contains all the possible characters. You can
ensure this by adding an alphabet to the text or pre-load the
frequency table with all possible characters.

Do some benchmark of your system and determine how well it
performs, try to estimate the time to encode or decode a text given
the length of the text. 

If you have time try to do some experiments where you change the size
of the alphabet, for example using only eight characters, the regular
alphabet, all ascii characters. You would of course have to find
suitable texts but you could of course work with a large text file and
filter out a list with only the characters from your selected alphabet.


To read a file you can use the following code:

\begin{verbatim}
read(File, N) ->
    {ok, Fd} = file:open(File, [read, binary]),
    {ok, Binary} = file:read(Fd, N),
    file:close(Fd),
    case unicode:characters_to_list(Binary, utf8) of
        {incomplete, List, _} ->
            List;
        List ->
            List
    end.
\end{verbatim}


\end{document}

